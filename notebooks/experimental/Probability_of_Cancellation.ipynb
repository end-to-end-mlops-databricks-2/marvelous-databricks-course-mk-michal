{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2271f65-0801-4d0a-bfeb-5592a93396c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Data Science\n",
    "\n",
    "Create a Probability-of-Cancellation model. Your work won't be assessed on whether you get the best model, but that you understand important concepts behind analyzing the data, feature engineering and model development and evaluation. Keep this section simple, clear and illustrative of your understanding of how to prototype a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fa01920-5cf4-443f-ace9-1878b2fb1340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DMgIWZaH9Bxj"
   },
   "source": [
    "# Data Science Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38fe500d-1bb7-4148-9f1b-35b607b972d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "LGu-avAzS48b"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:10.680649Z",
     "start_time": "2024-11-15T14:24:10.675901Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e03ca9c7-f9c2-433a-a3f7-01f565c6df46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8ZIukxdbQbjY"
   },
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "861b446c-3b8e-42ac-a56c-9e327305cc93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "v0l5OEtrS2ww"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "In this notebook, we would like you to develop a model to predict whether a reservation will cancel and describe what the model learned. \n",
    "\n",
    "* The label in the dataset is given as `is_canceled`.\n",
    "* For a complete description of dataset, visit the link: https://www.sciencedirect.com/science/article/pii/S2352340918315191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:47:33.504199Z",
     "start_time": "2024-11-15T15:47:33.303321Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2758aaa7-ff3a-4f93-ad5d-67cf4b5717cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "Zpih7K5PRm5h",
    "outputId": "0b3ed19e-173d-4a1c-cbcd-2454a8464e52"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/hotel_bookings.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6489edcd-d5bc-4079-8061-d2e1e672bf65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "960d8210-a921-4802-b6a9-630095ff79c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add arrival date into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c44a6dc-b4d0-4d8d-8df9-11edb0ffa7e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "month_mapping = {\n",
    "    'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "    'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "    'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "}\n",
    "\n",
    "df['arrival_date'] = df.apply(\n",
    "    lambda x: datetime.date(\n",
    "        int(x['arrival_date_year']), \n",
    "        month_mapping[x['arrival_date_month']], \n",
    "        int(x['arrival_date_day_of_month'])\n",
    "    ), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "854724c6-027f-43e3-af73-be3a718388b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6tTaFJE5WThl"
   },
   "source": [
    " ## Helpful EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b25a5ef2-f198-47e8-b75d-bc4c9ff4ee32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "City_Hotel = df[(df['hotel']== 'City Hotel')]\n",
    "resort_hotel= df[df['hotel']=='Resort Hotel']\n",
    "\n",
    "resort_hotel = resort_hotel.groupby('arrival_date')[['adr']].mean()\n",
    "City_Hotel = City_Hotel.groupby('arrival_date')[['adr']].mean()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,8), facecolor='#C38154')\n",
    "plt.title('Average Daily Rate in City and Resort Hotel', fontsize=30)\n",
    "plt.plot(resort_hotel.index,resort_hotel['adr'],label = 'Resort Hotel')\n",
    "plt.plot(City_Hotel.index,City_Hotel['adr'],label = 'City Hotel')\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc8cc98f-1147-44d8-95db-d9ee3a3e594a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can see clear sesonality with the average prices especially for resort hotel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:11.298237Z",
     "start_time": "2024-11-15T14:24:11.294945Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2a85def-dfbf-464f-92bf-5c8aca851fd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwx0-5mDdaea",
    "outputId": "91c22dbe-b66d-43f7-82cf-8bd888febb2c"
   },
   "outputs": [],
   "source": [
    "df['is_canceled'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:11.562753Z",
     "start_time": "2024-11-15T14:24:11.560657Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c797a6ce-9bde-43b6-9c31-6365a010f1aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:11.748802Z",
     "start_time": "2024-11-15T14:24:11.671377Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9802447-ed96-46ca-9d06-396ad228daab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null = pd.DataFrame({'Null Values' : df.isna().sum(), 'Percentage Null Values' : (df.isna().sum()) / (df.shape[0]) * (100)})\n",
    "null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e19a8c7-bb72-485c-a475-c2e0db895791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:11.914322Z",
     "start_time": "2024-11-15T14:24:11.882689Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb418de9-a2f0-4a74-9927-b5e185877eb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Based on the description, if the agent is nan, the booking did not come from the travel agency and same with the company. Therefore we can fill these values with 0s (as we dont have 0 index in the dataset)   \n",
    "df[['agent', 'company', 'children']] = df[['agent', 'company', 'children']].fillna(0)\n",
    "\n",
    "# For country fill missing values with \"Unknown\"\n",
    "df['country'] = df['country'].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:11.963538Z",
     "start_time": "2024-11-15T14:24:11.952033Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "990d0d10-3e5a-4077-b17c-dcafd9ef23af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# based on the dataset description, columns \"agent\" and \"company\" suppose to represent IDs of the booking agent and the company/entity that made the booking, therefore we convert the type to object so that we do not treat these columns as numeric for the analysis\n",
    "df[['agent', 'company']] = df[['agent', 'company']].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "184b1dc5-b91b-49b8-b498-7b2eb2010e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the dataset, we see that adults, children and babies are 0s at the same time sometimes, which is strange, we might decide whether to drop these lines or not based on the investigation and usefullness of these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:12.067281Z",
     "start_time": "2024-11-15T14:24:12.026901Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddae11e0-ff03-4deb-8f99-c69f47a9b24d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filter = (df.children == 0) & (df.adults == 0) & (df.babies == 0)\n",
    "display(df[filter])\n",
    "df = df[~filter]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a904d868-ce07-4b82-a790-c79e7da19d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83e58fff-06d5-48e5-b24d-012c1b876721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Explore numerical values and its correlations with is_cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:24.844483Z",
     "start_time": "2024-11-15T14:24:24.122208Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e955fd13-96b9-4859-b0b8-cf82b9a072ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (24, 12))\n",
    "\n",
    "numerical_df = df.select_dtypes(include=[np.number])\n",
    "corr = numerical_df.corr()\n",
    "sns.heatmap(corr, annot = True, linewidths = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:24.956834Z",
     "start_time": "2024-11-15T14:24:24.875877Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4543929c-be8b-4b5f-95e9-d67d0504326f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "correlation = numerical_df.corr()['is_canceled'].abs().sort_values(ascending = False)\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18bac7fe-69f5-4c50-a12e-6ebaacd2a214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Insights:\n",
    "- most correlated features with is_cancelled are lead_time, total_of_special_requests, required_car_parking_spaces, booking_changes, previous_cancellations. \n",
    "- The longer lead_time to the stay, the longer time there is to cancel\n",
    "- the more special requests, the less likely the reservation is to be canceled\n",
    "- Previous cancellation might indicate future cancellation as well. \n",
    "- Stays in weekend nights and stays in week nights are mutually correlated, so we use only one of these features   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:25.181254Z",
     "start_time": "2024-11-15T14:24:25.178622Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80f040dd-dc6a-48ab-95cc-fadd59f5a398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# numerical values to use for the model\n",
    "numerical_features = [\n",
    "    'lead_time', \n",
    "    'total_of_special_requests', \n",
    "    'required_car_parking_spaces', \n",
    "    'booking_changes', \n",
    "    'previous_cancellations', \n",
    "    'is_repeated_guest', \n",
    "    'previous_bookings_not_canceled', \n",
    "    'adr', \n",
    "    'agent', \n",
    "    'stays_in_week_nights'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:25.212327Z",
     "start_time": "2024-11-15T14:24:25.204127Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cc82456-0f6c-49cb-85f1-762269a4c27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_cancellation_per_category(category_column: str, minimal_category_count: int):\n",
    "    category_counts = df[category_column].value_counts()\n",
    "    categories = category_counts[category_counts > minimal_category_count]\n",
    "\n",
    "    # group by these agents and get percentage mean of cancelations\n",
    "\n",
    "    df_subset_categories = df[df[category_column].isin(categories.index)]\n",
    "    categories_grouped = df_subset_categories.groupby(category_column).is_canceled.mean().sort_values(ascending = False)\n",
    "\n",
    "    # plot bar plot for the groupby for the is_cancelled column\n",
    "    plt.figure(figsize = (12, 6))\n",
    "    categories_grouped.plot(kind = 'bar')\n",
    "    plt.title(f'{category_column} and their cancellation rates')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:27.569170Z",
     "start_time": "2024-11-15T14:24:25.348016Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95f1cdee-c483-4317-8f07-42a7f8d582b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "excluded_columns = ['reservation_status', 'reservation_status_date']\n",
    "columns = [c for c in df.select_dtypes(include = 'object').columns if c not in excluded_columns]\n",
    "for col in columns:\n",
    "    plot_cancellation_per_category(col, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e6ee135-6856-4f5e-9534-30bb432846cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cancelled_data= df[df['is_canceled']==1]\n",
    "top_10_country = cancelled_data['country'].value_counts()[:10]\n",
    "\n",
    "\n",
    "# Custom colors for the pie chart\n",
    "custom_colors = ['#FF6347', '#4682B4', '#7FFF00', '#FFD700', '#87CEEB', '#FFA07A', '#6A5ACD', '#FF69B4', '#40E0D0', '#DAA520']\n",
    "\n",
    "plt.figure(figsize=(8, 8), facecolor='#C38154')  # Set background color to a light brown\n",
    "plt.title('Top 10 countries with reservation canceled', color=\"black\")\n",
    "plt.pie(top_10_country, autopct='%.2f', labels=top_10_country.index, colors=custom_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf6cb130-199b-42fa-804a-4d762586a2cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Insights:\n",
    "- City hotels have a higher cancellation rate than resort hotels\n",
    "- Spring months have higher cancellation rates, on the opposite, January has the lowest (might be because of cheaper prices or special offeres in January)\n",
    "- Full board has the highest cancellation rate\n",
    "- Groups have the highest cancellation rate\n",
    "- Countries cancellation rate varies, so we remove them from the model prediction as we have a lot of countries and the model wouldnt be generic -> we might want to go back and investigate especially Portugal, for which we have the most data and it has the highest cancellation rate. \n",
    "- *strangest results are for the \"deposit_type\" for which we have 99 % of cancellations for Non Refund type. This makes no sense, so we should investigate why we have this results -> for now we remove it from the analysis.\n",
    "- We might want to investigate further the relationship between assigned_room_type and reserved_room_type. Especially with assigned room types with higher numbers than requested room types, we might expect lower cancellation rates (as we see for assigned rooms for K and I)   \n",
    "- We see big variation in \"agent\" and \"company\" features. This might be investigated futher, but for the sake of simplicity of this task, lets just company if the booking was made by a company or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:27.766187Z",
     "start_time": "2024-11-15T14:24:27.763186Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcb5fc7f-e989-49b6-b643-0e4975968dce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For the model prediction, we use these category columns\n",
    "categorical_features = [\n",
    "    'hotel', \n",
    "    'arrival_date_month', \n",
    "    'meal', \n",
    "    'market_segment', \n",
    "    'distribution_channel', \n",
    "    'reserved_room_type',\n",
    "    'reserved_room_type', \n",
    "    'customer_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adc9694b-314c-4fd7-ab71-962aacc79679",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For `agent` and `company` feature instead of adding all values into the model, lets only distinguished if the booking was done by agent or a company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:28.394041Z",
     "start_time": "2024-11-15T14:24:27.981109Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54bbac71-53fc-487b-9c37-2237c51ddf84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# assign each value in column agent that is greater than 0 to 1\n",
    "df.loc[df['agent'] > 0, 'agent'] = 1\n",
    "df.loc[df['company'] > 0, 'company'] = 1\n",
    "\n",
    "plot_cancellation_per_category('agent', 100)\n",
    "plot_cancellation_per_category('company', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:28.535165Z",
     "start_time": "2024-11-15T14:24:28.533043Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9fd4730-f034-40f4-866c-233add0c0676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# we see differences here, so lets add the features into numerical values\n",
    "numerical_features.extend(['agent', 'company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:28.676367Z",
     "start_time": "2024-11-15T14:24:28.655043Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e10442a4-fb45-46fe-abc2-82d24ce0c6a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Separate features and predicted value\n",
    "features = numerical_features + categorical_features\n",
    "df_categorical = df[categorical_features]\n",
    "df_numerical = df[numerical_features]\n",
    "y = df['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:28.931220Z",
     "start_time": "2024-11-15T14:24:28.827564Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73c3366a-0950-4829-96ed-aca69268f02e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# convert each categorical column in df_categorical into one-hot-encoging column\n",
    "df_categorical_dummies = pd.get_dummies(df_categorical).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:29.092293Z",
     "start_time": "2024-11-15T14:24:29.073921Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4e543ae-9416-4f70-a801-10cb93a8e32a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_numerical.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b645359-114d-45ec-9cb9-d32a7ed0374d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Baseline model\n",
    "\n",
    "We use Logistic Regression as a simple baseline. For this model, we need to scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:29.786012Z",
     "start_time": "2024-11-15T14:24:29.533765Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80eddb4c-d96c-4553-8c0d-2a9371006073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_numerical = StandardScaler().fit_transform(df_numerical)\n",
    "\n",
    "X = pd.concat([pd.DataFrame(X_numerical, columns = df_numerical.columns), df_categorical_dummies], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:28:46.112370Z",
     "start_time": "2024-11-15T14:28:43.328494Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3dc2466-1cc8-4a7a-8f44-eb245d564bff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kfolds = 4 # 4 = 75% train, 25% validation\n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "# Preprocessing, fitting, making predictions and scoring for every model:\n",
    "    # pack preprocessing of data and the model in a pipeline:\n",
    "\n",
    "# get cross validation score for each model:\n",
    "cv_results = cross_val_score(LogisticRegression(max_iter=1000), \n",
    "                             X, y, \n",
    "                             cv=split,\n",
    "                             scoring=\"f1\",\n",
    "                             n_jobs=-1)\n",
    "# output:\n",
    "min_score = round(min(cv_results), 4)\n",
    "max_score = round(max(cv_results), 4)\n",
    "mean_score = round(np.mean(cv_results), 4)\n",
    "std_dev = round(np.std(cv_results), 4)\n",
    "print(f\"Cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66b14733-7b8d-4a9d-b096-3c1dc9ce0975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Train random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:38:31.839743Z",
     "start_time": "2024-11-15T14:38:18.134464Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9aedc010-8443-4fa7-a366-993007d5bd09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train Gradient boosting model\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cv_results = cross_val_score(RandomForestClassifier(), \n",
    "                             X, y, \n",
    "                             cv=split,\n",
    "                             scoring=\"f1\",\n",
    "                             n_jobs=-1)\n",
    "# output:\n",
    "min_score = round(min(cv_results), 4)\n",
    "max_score = round(max(cv_results), 4)\n",
    "mean_score = round(np.mean(cv_results), 4)\n",
    "std_dev = round(np.std(cv_results), 4)\n",
    "print(f\"Cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T14:41:57.065932Z",
     "start_time": "2024-11-15T14:41:45.691346Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b36954de-e4c7-491e-86f4-46076e1216f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# fit RandomForrest model and print feature importance. Split to train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, preds)\n",
    "print(f\"Accuracy score: {round(score, 4)}\")\n",
    "\n",
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, preds)\n",
    "print(f\"F1 score: {round(f1, 4)}\")\n",
    "\n",
    "# plot feature importance -> sort features by importance\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "         color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Probability_of_Cancellation",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
